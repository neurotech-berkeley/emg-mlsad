{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> Select file to analyze:\n",
      "\n",
      "   0 : 0210_second.npz\n",
      "   1 : 0210_first.npz\n",
      "   2 : 0225_arjun.npz\n",
      "\n",
      "OK, opening:  0225_arjun.npz\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import mne\n",
    "import mne_qt_browser\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# execute ls, sort files by date created\n",
    "output = subprocess.run([\"ls -t ../data_named\"], stdout=subprocess.PIPE, shell=True, text=True)\n",
    "# show only the last 5 files, line by line\n",
    "files = output.stdout.split(\"\\n\")[:-1][:5]\n",
    "filename = None\n",
    "i = 0\n",
    "print(\"\\n>> Select file to analyze:\\n\")\n",
    "for file in files:\n",
    "    print(\"  \", i, \":\", file)\n",
    "    i += 1\n",
    "index = input(\"\\n>> \")\n",
    "if index == \"\":\n",
    "    index = 0 # if no input, default to the most recent file\n",
    "    filename = files[index]\n",
    "    print(\"\\nOK, most recent file: \", filename)\n",
    "else:\n",
    "    index = int(index)\n",
    "    filename = files[index]\n",
    "    print(\"\\nOK, opening: \", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction\n",
    "import scipy.signal as signal\n",
    "import scipy.stats as stats\n",
    "\n",
    "class DataBuilder:\n",
    "    def __init__(self, sfreq):\n",
    "        self.sfreq = sfreq\n",
    "\n",
    "    def load_data(self, data_path):\n",
    "        # Load the .npz file\n",
    "        data = np.load(data_path, allow_pickle=True)\n",
    "        labels = []\n",
    "        windows = []\n",
    "        for key in data.files:\n",
    "            label = data[key].item()['label']\n",
    "            window = data[key].item()['data']\n",
    "            labels.append(label)\n",
    "            windows.append(window)\n",
    "        # dropping the first window because it's \"rest\"\n",
    "        # drop the last window too\n",
    "        return windows[1:-1], labels[1:-1]\n",
    "    \n",
    "    def load_window(self, data_path, index):\n",
    "        # Load the .npz file\n",
    "        windows, labels = self.load_data(data_path)\n",
    "        windows = self.preprocess_data(windows)\n",
    "        return windows[index], labels[index]\n",
    "\n",
    "    def preprocess_data(self, windows):\n",
    "        # remove the first two columns of each window (millis and hall sensor)\n",
    "        processed_windows = []\n",
    "        for window in windows:\n",
    "            window = np.delete(window, [0,1], axis=1)\n",
    "            processed_windows.append(window)\n",
    "        \n",
    "        print(\"Printing some stats!\\n====================\")\n",
    "        print(\"Number of samples:\", len(processed_windows))\n",
    "        print(\"Number of channels:\", len(processed_windows[0][0]))\n",
    "        print(\"====================\\n\")\n",
    "\n",
    "        return processed_windows\n",
    "    \n",
    "    def create_feature_vector(self, window):\n",
    "        # window has shape samples x channels\n",
    "        features = []\n",
    "        print(\"Window shape:\", window.shape)\n",
    "        for channel in window.T:\n",
    "            # extract mean and std\n",
    "            mean = np.mean(channel)\n",
    "            std = np.std(channel)\n",
    "\n",
    "            # demean and normalize\n",
    "            channel = channel - np.mean(channel)\n",
    "            channel = channel / np.std(channel)\n",
    "\n",
    "            # calculate features\n",
    "            kurtosis = stats.kurtosis(channel)\n",
    "            skew = stats.skew(channel)\n",
    "            # find peaks\n",
    "            peaks, _ = signal.find_peaks(channel)\n",
    "            num_peaks = len(peaks)\n",
    "            # find zero crossings\n",
    "            zero_crossings = np.where(np.diff(np.sign(channel)))[0]\n",
    "            num_zero_crossings = len(zero_crossings)\n",
    "\n",
    "            # IEMG\n",
    "            iemg = np.sum(np.abs(channel))\n",
    "            # print(\"IEMG:\", iemg)\n",
    "\n",
    "            # MAV\n",
    "            mav = np.mean(np.abs(channel))\n",
    "            # print(\"MAV:\", mav)\n",
    "\n",
    "            # SSI\n",
    "            ssi = np.sum(np.square(channel))\n",
    "            # print(\"SSI:\", ssi)\n",
    "\n",
    "            # RMS\n",
    "            rms = np.sqrt(np.mean(np.square(channel)))\n",
    "            # print(\"RMS:\", rms)\n",
    "\n",
    "            # VAR\n",
    "            var = np.var(channel)\n",
    "            # print(\"VAR:\", var)\n",
    "\n",
    "            # Myopulse Percentage Rate\n",
    "            t_mmp = 0.1\n",
    "            mmp = np.sum(np.abs(channel) > t_mmp) / len(channel)\n",
    "            # print(\"MMP:\", mmp)\n",
    "\n",
    "            # Waveform Length\n",
    "            wl = np.sum(np.abs(np.diff(channel)))\n",
    "            # print(\"WL:\", wl)\n",
    "\n",
    "            # DAMV\n",
    "            damv = np.mean(np.abs(np.diff(channel)))\n",
    "            # print(\"DAMV:\", damv)\n",
    "\n",
    "            # M2\n",
    "            m2 = np.sum(np.square(np.diff(channel)))\n",
    "            # print(\"M2:\", m2)\n",
    "\n",
    "            # DVARV\n",
    "            dvarv = np.mean(np.square(np.diff(channel)))\n",
    "            # print(\"DVARV:\", dvarv)\n",
    "\n",
    "            # DASDV\n",
    "            dasdv = np.sqrt(np.mean(dvarv))\n",
    "            # print(\"DASDV:\", dasdv)\n",
    "\n",
    "            # WAMP\n",
    "            t_wamp = 0.1\n",
    "            wamp = np.sum(np.abs(np.diff(channel)) > t_wamp)\n",
    "            # print(\"WAMP:\", wamp)\n",
    "\n",
    "            # inegerated absolute of second derivative\n",
    "            iasd = np.sum(np.abs(np.diff(np.diff(channel))))\n",
    "\n",
    "            # integrated absolute third derivative\n",
    "            iatd = np.sum(np.abs(np.diff(np.diff(np.diff(channel)))))\n",
    "\n",
    "            # integerated exponential of absolute value\n",
    "            # ieav = np.sum(np.exp(np.abs(channel)))\n",
    "            # print(\"IEAV:\", ieav)\n",
    "\n",
    "            # integerated absolute log value\n",
    "            # ialv = np.sum(np.log(np.abs(channel) + 0.1))\n",
    "            # print(\"IALV:\", ialv)\n",
    "            # print(np.min(channel))\n",
    "            # print(np.max(channel))\n",
    "            # print(np.isnan(channel).any())\n",
    "\n",
    "            # integrated exponential\n",
    "            ie = np.sum(np.exp(channel))\n",
    "\n",
    "            features.append(kurtosis)\n",
    "            features.append(skew)\n",
    "            features.append(num_peaks)\n",
    "            features.append(num_zero_crossings)\n",
    "            # features.append(mean)\n",
    "            # features.append(std)\n",
    "            #features.append(iemg)\n",
    "            # features.append(mav)\n",
    "            #features.append(ssi)\n",
    "            # features.append(rms)\n",
    "            features.append(var)\n",
    "            #features.append(mmp)\n",
    "            #features.append(wl)\n",
    "            # features.append(damv)\n",
    "            #features.append(m2)\n",
    "            #features.append(dvarv)\n",
    "            #features.append(dasdv)\n",
    "            #features.append(wamp)\n",
    "            #features.append(iasd)\n",
    "            #features.append(iatd)\n",
    "            # features.append(ieav)\n",
    "            # features.append(ialv)\n",
    "            #features.append(ie)\n",
    "\n",
    "        features = np.array(features)\n",
    "        return features\n",
    "\n",
    "    def create_feature_matrix(self, windows):\n",
    "        # windows has shape windows x samples x channels\n",
    "        feature_matrix = []\n",
    "        for window in windows:\n",
    "            feature_vector = self.create_feature_vector(window)\n",
    "            feature_matrix.append(feature_vector)\n",
    "\n",
    "        feature_matrix = np.array(feature_matrix)\n",
    "        print(\"Feature matrix shape:\", feature_matrix.shape)\n",
    "        return feature_matrix\n",
    "    \n",
    "    def get_labels(self):\n",
    "        return self.labels\n",
    "\n",
    "    def build_data(self, data_path):\n",
    "        # Load data\n",
    "        windows, labels = self.load_data(data_path)\n",
    "        print(\"Number of labeled samples:\", len(windows))\n",
    "\n",
    "        # Preprocess data\n",
    "        windows = self.preprocess_data(windows)\n",
    "\n",
    "        # Create feature matrix\n",
    "        X = self.create_feature_matrix(windows)\n",
    "\n",
    "        # Get labels\n",
    "        y = labels\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labeled samples: 119\n",
      "Printing some stats!\n",
      "====================\n",
      "Number of samples: 119\n",
      "Number of channels: 4\n",
      "====================\n",
      "\n",
      "Window shape: (843, 4)\n",
      "Window shape: (1015, 4)\n",
      "Window shape: (776, 4)\n",
      "Window shape: (889, 4)\n",
      "Window shape: (1117, 4)\n",
      "Window shape: (710, 4)\n",
      "Window shape: (736, 4)\n",
      "Window shape: (904, 4)\n",
      "Window shape: (677, 4)\n",
      "Window shape: (969, 4)\n",
      "Window shape: (914, 4)\n",
      "Window shape: (924, 4)\n",
      "Window shape: (1045, 4)\n",
      "Window shape: (1077, 4)\n",
      "Window shape: (921, 4)\n",
      "Window shape: (1070, 4)\n",
      "Window shape: (706, 4)\n",
      "Window shape: (916, 4)\n",
      "Window shape: (831, 4)\n",
      "Window shape: (592, 4)\n",
      "Window shape: (827, 4)\n",
      "Window shape: (1042, 4)\n",
      "Window shape: (1125, 4)\n",
      "Window shape: (1113, 4)\n",
      "Window shape: (1115, 4)\n",
      "Window shape: (933, 4)\n",
      "Window shape: (1005, 4)\n",
      "Window shape: (1186, 4)\n",
      "Window shape: (848, 4)\n",
      "Window shape: (946, 4)\n",
      "Window shape: (921, 4)\n",
      "Window shape: (767, 4)\n",
      "Window shape: (1130, 4)\n",
      "Window shape: (877, 4)\n",
      "Window shape: (623, 4)\n",
      "Window shape: (1069, 4)\n",
      "Window shape: (1218, 4)\n",
      "Window shape: (800, 4)\n",
      "Window shape: (924, 4)\n",
      "Window shape: (927, 4)\n",
      "Window shape: (1096, 4)\n",
      "Window shape: (744, 4)\n",
      "Window shape: (1128, 4)\n",
      "Window shape: (784, 4)\n",
      "Window shape: (849, 4)\n",
      "Window shape: (754, 4)\n",
      "Window shape: (750, 4)\n",
      "Window shape: (626, 4)\n",
      "Window shape: (602, 4)\n",
      "Window shape: (779, 4)\n",
      "Window shape: (885, 4)\n",
      "Window shape: (782, 4)\n",
      "Window shape: (1037, 4)\n",
      "Window shape: (808, 4)\n",
      "Window shape: (585, 4)\n",
      "Window shape: (587, 4)\n",
      "Window shape: (634, 4)\n",
      "Window shape: (944, 4)\n",
      "Window shape: (609, 4)\n",
      "Window shape: (1015, 4)\n",
      "Window shape: (905, 4)\n",
      "Window shape: (999, 4)\n",
      "Window shape: (753, 4)\n",
      "Window shape: (744, 4)\n",
      "Window shape: (1057, 4)\n",
      "Window shape: (1038, 4)\n",
      "Window shape: (1178, 4)\n",
      "Window shape: (817, 4)\n",
      "Window shape: (949, 4)\n",
      "Window shape: (595, 4)\n",
      "Window shape: (891, 4)\n",
      "Window shape: (912, 4)\n",
      "Window shape: (895, 4)\n",
      "Window shape: (1032, 4)\n",
      "Window shape: (659, 4)\n",
      "Window shape: (1120, 4)\n",
      "Window shape: (823, 4)\n",
      "Window shape: (1138, 4)\n",
      "Window shape: (815, 4)\n",
      "Window shape: (1130, 4)\n",
      "Window shape: (836, 4)\n",
      "Window shape: (1162, 4)\n",
      "Window shape: (723, 4)\n",
      "Window shape: (700, 4)\n",
      "Window shape: (1009, 4)\n",
      "Window shape: (1080, 4)\n",
      "Window shape: (620, 4)\n",
      "Window shape: (643, 4)\n",
      "Window shape: (679, 4)\n",
      "Window shape: (771, 4)\n",
      "Window shape: (1067, 4)\n",
      "Window shape: (955, 4)\n",
      "Window shape: (800, 4)\n",
      "Window shape: (1039, 4)\n",
      "Window shape: (1099, 4)\n",
      "Window shape: (1088, 4)\n",
      "Window shape: (1033, 4)\n",
      "Window shape: (866, 4)\n",
      "Window shape: (605, 4)\n",
      "Window shape: (657, 4)\n",
      "Window shape: (977, 4)\n",
      "Window shape: (866, 4)\n",
      "Window shape: (1117, 4)\n",
      "Window shape: (1101, 4)\n",
      "Window shape: (606, 4)\n",
      "Window shape: (817, 4)\n",
      "Window shape: (1030, 4)\n",
      "Window shape: (619, 4)\n",
      "Window shape: (1028, 4)\n",
      "Window shape: (615, 4)\n",
      "Window shape: (786, 4)\n",
      "Window shape: (1133, 4)\n",
      "Window shape: (1043, 4)\n",
      "Window shape: (629, 4)\n",
      "Window shape: (733, 4)\n",
      "Window shape: (851, 4)\n",
      "Window shape: (743, 4)\n",
      "Window shape: (875, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/js/fb9kwys10ln8jgq1bxxqg0tr0000gn/T/ipykernel_33326/119856948.py:54: RuntimeWarning: divide by zero encountered in divide\n",
      "  channel = channel / np.std(channel)\n",
      "/var/folders/js/fb9kwys10ln8jgq1bxxqg0tr0000gn/T/ipykernel_33326/119856948.py:54: RuntimeWarning: invalid value encountered in divide\n",
      "  channel = channel / np.std(channel)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window shape: (1073, 4)\n",
      "Feature matrix shape: (119, 20)\n",
      "Printing some stats!\n",
      "====================\n",
      "Number of samples: 119\n",
      "Number of channels: 4\n",
      "====================\n",
      "\n",
      "X shape: (119, 20)\n",
      "y shape: 119\n"
     ]
    }
   ],
   "source": [
    "# run feature extraction\n",
    "npz_file_path = f\"../data_named/{filename}\"\n",
    "\n",
    "data_builder = DataBuilder(sfreq=1000)\n",
    "X, y = data_builder.build_data(data_path=npz_file_path)\n",
    "\n",
    "window_4, label_4 = data_builder.load_window(npz_file_path, 4)\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "# drop nans in X_test\n",
    "y_test = np.array(y_test)\n",
    "y_test = y_test[~np.isnan(X_test).any(axis=1)]\n",
    "X_test = X_test[~np.isnan(X_test).any(axis=1)]\n",
    "y_train = np.array(y_train)\n",
    "y_train = y_train[~np.isnan(X_train).any(axis=1)]\n",
    "X_train = X_train[~np.isnan(X_train).any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logitsic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38, 20)\n",
      "Time taken: 0.00016808509826660156\n",
      "Accuracy: 0.00\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "thumb-to-index       0.00      0.00      0.00       1.0\n",
      "thumb-to-pinky       0.00      0.00      0.00       0.0\n",
      "\n",
      "      accuracy                           0.00       1.0\n",
      "     macro avg       0.00      0.00      0.00       1.0\n",
      "  weighted avg       0.00      0.00      0.00       1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bei/anaconda3/envs/ntb/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bei/anaconda3/envs/ntb/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/bei/anaconda3/envs/ntb/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/bei/anaconda3/envs/ntb/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/bei/anaconda3/envs/ntb/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/bei/anaconda3/envs/ntb/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/bei/anaconda3/envs/ntb/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# fit the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "print(X_test.shape)\n",
    "import time\n",
    "start = time.time()\n",
    "y_pred = model.predict(X_test[0,:].reshape(1, -1))\n",
    "print(\"Time taken:\", time.time() - start)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(np.array([y_test[0]]), y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Additional metrics\n",
    "print(classification_report(np.array([y_test[0]]), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thumb-to-index'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_inference(window, model):\n",
    "#     feature_vector = data_builder.create_feature_vector(window)\n",
    "#     feature_vector = np.array([feature_vector])\n",
    "#     print(\"Feature vector shape:\", feature_vector.shape)\n",
    "#     prediction = model.predict(feature_vector)\n",
    "#     return prediction\n",
    "\n",
    "# prediction = run_inference(window_4, model)\n",
    "# print(\"Prediction:\", prediction)\n",
    "# print(\"Actual:\", label_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        clench       0.00      0.00      0.00         9\n",
      "          rest       0.44      0.57      0.50         7\n",
      "thumb-to-index       0.44      0.62      0.52        13\n",
      "thumb-to-pinky       0.29      0.22      0.25         9\n",
      "\n",
      "      accuracy                           0.37        38\n",
      "     macro avg       0.29      0.35      0.32        38\n",
      "  weighted avg       0.30      0.37      0.33        38\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bei/anaconda3/envs/ntb/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "# fit the model\n",
    "qda = QuadraticDiscriminantAnalysis(tol=1e-1)\n",
    "qda.fit(X_train, y_train)\n",
    "y_pred = qda.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Additional metrics\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.34\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        clench       0.57      0.44      0.50         9\n",
      "          rest       0.18      0.29      0.22         7\n",
      "thumb-to-index       0.25      0.15      0.19        13\n",
      "thumb-to-pinky       0.42      0.56      0.48         9\n",
      "\n",
      "      accuracy                           0.34        38\n",
      "     macro avg       0.35      0.36      0.35        38\n",
      "  weighted avg       0.35      0.34      0.34        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# fit the model\n",
    "lda = LinearDiscriminantAnalysis(solver='lsqr')\n",
    "lda.fit(X_train, y_train)\n",
    "y_pred = lda.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Additional metrics\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# confusion matrix for y_test and y_pred\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remap to classify only two classes of movements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['thumb-to-index', 'thumb-to-pinky', 'clench', 'rest',\n",
       "       'thumb-to-index', 'thumb-to-pinky', 'clench', 'rest',\n",
       "       'thumb-to-index', 'thumb-to-pinky', 'clench', 'rest',\n",
       "       'thumb-to-index', 'thumb-to-pinky', 'clench', 'rest',\n",
       "       'thumb-to-index', 'thumb-to-pinky', 'clench', 'rest',\n",
       "       'thumb-to-index', 'thumb-to-pinky', 'clench', 'rest',\n",
       "       'thumb-to-index', 'thumb-to-pinky', 'clench', 'rest',\n",
       "       'thumb-to-index', 'thumb-to-pinky', 'clench', 'rest',\n",
       "       'thumb-to-index', 'thumb-to-pinky', 'clench', 'rest',\n",
       "       'thumb-to-index', 'thumb-to-pinky', 'clench', 'rest',\n",
       "       'thumb-to-index', 'thumb-to-pinky', 'clench', 'rest',\n",
       "       'thumb-to-index', 'thumb-to-pinky', 'clench', 'rest',\n",
       "       'thumb-to-index', 'thumb-to-pinky', 'clench', 'rest',\n",
       "       'thumb-to-index', 'thumb-to-pinky', 'clench', 'rest',\n",
       "       'thumb-to-index', 'thumb-to-pinky', 'clench', 'rest',\n",
       "       'thumb-to-index', 'thumb-to-pinky', 'clench', 'rest',\n",
       "       'thumb-to-index', 'thumb-to-pinky', 'clench', 'rest',\n",
       "       'thumb-to-index', 'thumb-to-pinky', 'clench', 'rest',\n",
       "       'thumb-to-index', 'thumb-to-pinky', 'clench', 'rest',\n",
       "       'thumb-to-index', 'thumb-to-pinky', 'clench', 'rest',\n",
       "       'thumb-to-index', 'thumb-to-pinky', 'clench', 'rest',\n",
       "       'thumb-to-index', 'thumb-to-pinky', 'clench', 'rest',\n",
       "       'thumb-to-index', 'thumb-to-pinky', 'clench', 'rest',\n",
       "       'thumb-to-index', 'thumb-to-pinky', 'clench', 'rest',\n",
       "       'thumb-to-index', 'thumb-to-pinky', 'clench', 'rest',\n",
       "       'thumb-to-index', 'thumb-to-pinky', 'clench', 'rest',\n",
       "       'thumb-to-index', 'thumb-to-pinky', 'clench', 'rest',\n",
       "       'thumb-to-index', 'thumb-to-pinky', 'clench', 'rest',\n",
       "       'thumb-to-index', 'thumb-to-pinky', 'clench', 'rest',\n",
       "       'thumb-to-index', 'thumb-to-pinky', 'clench'], dtype='<U14')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remap labels\n",
    "thumb_labels = [\"thumb-to-index\", \"thumb-to-pinky\"]\n",
    "y_remap = []\n",
    "for label in y:\n",
    "    if label in thumb_labels:\n",
    "        y_remap.append(\"thumb\")\n",
    "    if label == \"clench\":\n",
    "        y_remap.append(\"clench\")\n",
    "    if label == \"rest\":\n",
    "        y_remap.append(\"rest\")\n",
    "y_remap = np.array(y_remap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of rest\n",
    "idx = (y_remap != \"rest\")\n",
    "X_remap = X[idx]\n",
    "y_remap = y_remap[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 20)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_remap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_remap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "X_train_rm, X_test_rm, y_train_rm, y_test_rm = train_test_split(X_remap, y_remap, test_size=0.2, random_state=42)\n",
    "# drop nans\n",
    "y_test_rm = np.array(y_test_rm)\n",
    "y_test_rm = y_test_rm[~np.isnan(X_test_rm).any(axis=1)]\n",
    "X_test_rm = X_test_rm[~np.isnan(X_test_rm).any(axis=1)]\n",
    "y_train_rm = np.array(y_train_rm)\n",
    "y_train_rm = y_train_rm[~np.isnan(X_train_rm).any(axis=1)]\n",
    "X_train_rm = X_train_rm[~np.isnan(X_train_rm).any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      clench       0.57      0.80      0.67         5\n",
      "       thumb       0.83      0.62      0.71         8\n",
      "\n",
      "    accuracy                           0.69        13\n",
      "   macro avg       0.70      0.71      0.69        13\n",
      "weighted avg       0.73      0.69      0.70        13\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bei/anaconda3/envs/ntb/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# logistic\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# fit the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_rm, y_train_rm)\n",
    "y_pred_rm = model.predict(X_test_rm)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_rm, y_pred_rm)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Additional metrics\n",
    "print(classification_report(y_test_rm, y_pred_rm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      clench       0.57      0.80      0.67         5\n",
      "       thumb       0.83      0.62      0.71         8\n",
      "\n",
      "    accuracy                           0.69        13\n",
      "   macro avg       0.70      0.71      0.69        13\n",
      "weighted avg       0.73      0.69      0.70        13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scaling\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train_rm)\n",
    "X_train_rm_std = sc.transform(X_train_rm)\n",
    "X_test_rm_std = sc.transform(X_test_rm)\n",
    "\n",
    "# fit the model\n",
    "svm = SVC(kernel='linear', random_state=42)\n",
    "svm.fit(X_train_rm_std, y_train_rm)\n",
    "y_pred_rm = svm.predict(X_test_rm_std)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_rm, y_pred_rm)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Additional metrics\n",
    "print(classification_report(y_test_rm, y_pred_rm))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
